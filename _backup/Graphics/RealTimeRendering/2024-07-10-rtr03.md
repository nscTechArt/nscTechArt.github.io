---
title: Chapter 3 The Graphics Processing Unit
date: 2024-07-10 16:06 +0800
categories: [Graphics, Real Time Rendering]
media_subpath: /assets/img/Graphics/RealTimeRendering/
---

### 3.1 Data-Parallel Architectures

不同的处理器架构会使用各种策略来避免停顿。

CPU经过优化，用于处理各种负责的数据结构与大型代码库。CPU虽然可以有多个处理器，但大多是串行运行代码，SIMD向量处理是少数的例外。为了最小化延迟的影响，CPU的大部分芯片面积由快速本地缓存组成，这些缓存填充了可能下一个需要的数据。CPU还通过使用诸如分支预测、指令重排、寄存器重命名和缓存预取等技巧来避免停顿

GPU采用了不同的策略。GPU的大部分芯片面积专用于大量的处理器集合，称为着色器核心，通常数量以千计。GPU是一个流处理器，其中有序的相似数据集按顺序处理。由于这种相似性——例如，一组顶点或像素——GPU可以以大规模并行的方式处理这些数据。另一个重要因素是，这些调用尽可能独立，因此它们不需要邻近调用的信息，也不共享可写内存位置。这个规则有时会被打破以允许新的和有用的功能，但这样的例外会带来潜在的延迟，因为一个处理器可能会等待另一个处理器完成其工作。

GPU被优化以实现*throughput*，即处理数据的最大速度。然而这种优化也是有代价的，因为GPU的芯片面积较少用于缓存和控制逻辑，因此每个着色器核心的延迟通常比CPU处理器高得多。

假设有一个mesh被光栅化后，有2000个像素片段需要处理，每个片段都需要调用一次像素着色器程序。如果我们的GPU上只有一个着色器处理器，那么则该处理器需要调用2000次像素着色器程序。

我们现在来看一下这个着色器处理器的工作流程：

- **开始执行**：着色器处理器开始为第一个片段执行着色器程序
- **算数操作**：处理器在寄存器中的值上执行一些算数操作，寄存器是本地的，访问速度非常快，因此不会发生停顿。
- **纹理访问**：接下来，，处理器需要访问纹理数据，例如，获取某个表面位置的纹理颜色。纹理存储在独立的内存中，不是着色器程序的本地内存，访问纹理可能比较耗时。
- **等待纹理数据**：一次纹理数据获取可能需要数百到数千个时钟周期。在此期间，着色器处理器会停顿，等待数据返回

为了提升性能，可以为每个片段提供一些局部寄存器存储空间。当处理器等待纹理数据时，它可以切换到其他片段继续执行，从而避免浪费等待时间。当遇到纹理获取的停顿时，处理器可以切换到下一个片段继续执行。尽管单个片段的执行时间变长，但由于处理器始终在工作，所有片段的整体执行时间会显著减少。

**延迟隐藏**：

这种通过切换片段来隐藏延迟的方法是GPU架构的一大优势。它确保了处理器在等待数据时可以继续处理其他任务，从而提高整体效率。

**单指令多数据SIMD**：

- **定义**：SIMD是一种处理器架构，它允许多个处理单元同时执行相同的指令，但处理不同的数据。
- **优势**：与独立处理单元相比，SIMD大大减少了硬件资源的需求，因为它只需要一个指令控制单元。
- **线程和warp/wavefront**：
  - 现代GPU术语中，每个像素片段的着色器调用称为一个线程。
  - 使用相同着色器程序的线程被分组为warp（NVIDIA）或wavefront（AMD）。
  - 一个warp或wavefront通常包含多个线程，这些线程由多个着色器核心并行执行。

**SIMD通道：**

每个线程被映射到一个SIMD通道，通道数量通常从8到64不等。这种架构使得GPU在处理大量相似任务（如图形渲染）时非常高效。

### 3.2 GPU Pipeline Overview

